{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "num_sb_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# classification of one card"
      ],
      "metadata": {
        "id": "gMwqVEu-WU5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dictonary from labels(str) to int\n",
        "\n",
        "num_full_dict_iapr={\n",
        "'AS': 0, '2S':1, '3S':2, '4S':3, '5S':4, '6S':5, '7S':6,\n",
        "'8S':7, '9S':8, '10S':9, 'JS':10, 'QS':11, 'KS':12,\n",
        "'AH': 0, '2H': 1, '3H': 2, '4H': 3, '5H': 4, '6H': 5,\n",
        "'7H':6, '8H':7, '9H':8, '10H':9, 'JH': 10, 'QH': 11,\n",
        "'KH':12,\n",
        "'AC': 0, '2C': 1, '3C': 2, '4C': 3, '5C': 4, '6C': 5,\n",
        "'7C':6, '8C':7, '9C':8, '10C':9, 'JC': 10, 'QC': 11,\n",
        "'KC':12,\n",
        "'AD': 0, '2D': 1, '3D': 2, '4D': 3, '5D': 4, '6D': 5,\n",
        "'7D':6, '8D':7, '9D':8, '10D':9, 'JD': 10, 'QD': 11,\n",
        "'KD':12, 'null':13}\n",
        "inv_num_dic={'0':'A','1':'2','2':'3','3':'4','4':'5','5':'6','6':'7','7':'8','8':'9','9':'10','10':'J','11':'Q','12':'K','13':'N'}\n",
        "\n",
        "\n",
        "sb_full_dict_iapr={'D':0,'H':1,'S':2,'C':3,'u':4}\n",
        "inv_sb_dic = {'0':'D','1':'H','2':'S','3':'C','4':'N'}\n"
      ],
      "metadata": {
        "id": "-Eq_5V6nWWhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Model\n",
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self,classes=14):\n",
        "    super(MLP, self).__init__()\n",
        "    self.fc1 = torch.nn.Linear(3000,500)\n",
        "    self.fc3 = torch.nn.Linear(500,100)\n",
        "    self.fc4 = torch.nn.Linear(100,classes)\n",
        "\n",
        "  def forward(self,input):\n",
        "    input = torch.nn.functional.relu(self.fc1(input))\n",
        "    input = self.fc3(input)\n",
        "    input = self.fc4(input)\n",
        "    return input\n",
        "\n",
        "model_num = MLP(classes=14)\n",
        "path_num = '/content/drive/MyDrive/iapr/Models/num_2022-06-03-06-33.pt'\n",
        "model_num.load_state_dict(torch.load(path_num))\n",
        "mn=model_num.eval()\n",
        "print('mn:',mn)\n",
        "\n",
        "model_sb = MLP(classes=5)\n",
        "path_sb = '/content/drive/MyDrive/iapr/Models/sb_2022-06-03-05-51.pt'\n",
        "model_sb.load_state_dict(torch.load(path_sb))\n",
        "ms=model_sb.eval()\n",
        "print('ms:',ms)"
      ],
      "metadata": {
        "id": "0J3Ftj77WZOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load raw data\n",
        "\"\"\"\n",
        "  ims_num: ndarray [Image, Image]\n",
        "  ims_sb: ndarray [Image, Image]\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "path = '/content/drive/MyDrive/iapr/project/data/train'\n",
        "df = pd.read_csv(os.path.join(path,'updated_train_labels.csv'),keep_default_na=False) #filelink: https://drive.google.com/file/d/1eVEAf7qZaTpfqygPjPsCIT5nNrsKcMk7/view?usp=sharing\n",
        "\n",
        "# label for num classification\n",
        "labelNum=[]\n",
        "try:\n",
        "  for i in range(28):\n",
        "    # pdb.set_trace()\n",
        "    # for t in ['P1.1','P1.2','P2.1','P2.2','P3.1','P3.2','P4.1','P4.2','T1','T2','T3','T4','T5',]:\n",
        "    for t in ['P1.1','P1.2','P2.1','P2.2','P3.1','P3.2','P4.1','P4.2']:\n",
        "      tmp = df.iloc[i]\n",
        "      labelNum.append(num_full_dict_iapr[tmp[t]])  \n",
        "  labelNum = np.array(labelNum)\n",
        "except KeyError:\n",
        "  print(i)\n",
        "  print(t)\n",
        "  print(tmp[t])\n",
        "\n",
        "# label for symbol classification\n",
        "labelSb=[]\n",
        "try:\n",
        "  for i in range(28):\n",
        "    for t in ['P1.1','P1.2','P2.1','P2.2','P3.1','P3.2','P4.1','P4.2']:\n",
        "      tmp = df.iloc[i]\n",
        "      if len(tmp[t])==3:\n",
        "        s = tmp[t][2:3]\n",
        "      else:\n",
        "        s = tmp[t][1:2]\n",
        "      labelSb.append(sb_full_dict_iapr[s])\n",
        "  labelSb = np.array(labelSb)\n",
        "except KeyError:\n",
        "  print(i)\n",
        "  print(t)\n",
        "  print(tmp[t])\n",
        "\n",
        "\n",
        "# data for num classification \n",
        "ims_num=np.load(\"/content/drive/MyDrive/iapr/project/data/total_cropped_cards/total_P_digits.npy\") # 140,348,228,3 Num,H,W,C\n",
        "\n",
        "# data for symbol classification\n",
        "ims_sb=np.load(\"/content/drive/MyDrive/iapr/project/data/total_cropped_cards/total_P_symbols.npy\") # 140,348,228,3 Num,H,W,C\n"
      ],
      "metadata": {
        "id": "us7eCzTpWfFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# execute demo\n"
      ],
      "metadata": {
        "id": "xiBpm-lGW2zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "i=100\n",
        "im_num=Image.fromarray(ims_num[i].astype(np.uint8)).resize([50,60])\n",
        "plt.imshow(im_num)\n",
        "plt.show()\n",
        "im_num = im_num.convert(\"L\")\n",
        "im_num = torch.from_numpy(np.array(im_num).flatten().astype(np.float32))\n",
        "\n",
        "im_sb = Image.fromarray(ims_sb[i].astype(np.uint8)).resize([50,60])\n",
        "plt.imshow(im_sb)\n",
        "plt.show()\n",
        "im_sb = im_sb.convert(\"L\")\n",
        "im_sb = torch.from_numpy(np.array(im_sb).flatten().astype(np.float32))\n",
        "\n",
        "outputs_num = model_num(im_num)\n",
        "_, pred_num = torch.max(outputs_num.data, dim=0)\n",
        "# print()\n",
        "\n",
        "outputs_sb = model_sb(im_sb)\n",
        "_, pred_sb = torch.max(outputs_sb.data, dim=0)\n",
        "# print(pred_sb.item())\n",
        "print(inv_num_dic[str(pred_num.item())]+inv_sb_dic[str(pred_sb.item())])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "51BpVLn_WyyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}